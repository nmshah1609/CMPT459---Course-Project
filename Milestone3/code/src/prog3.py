# -*- coding: utf-8 -*-
"""notebook3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xEC_ynDXz_mbpiQORqYqeAjcN8V9sowp
"""

!pip install ppscore
 !pip install imblearn

import ppscore as pps
import pandas as pd 
import numpy as np 

import random
import os

from sklearn import preprocessing
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold

from sklearn.metrics import accuracy_score, make_scorer, recall_score, precision_score, f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from imblearn.over_sampling import SMOTE
import collections

"""#Loading Dataset"""

#uploading dataset
from google.colab import drive
drive.mount('/content/gdrive/')

os.chdir("/content/gdrive/My Drive/459")

os.chdir("/content/gdrive/My Drive/459")

ls

"""#Reading Dataset"""

data = pd.read_csv("/content/gdrive/My Drive/459/Final/milestone1.csv")
print(data.describe())

"""#Preprocessing"""

data = data.drop('Last_Update',axis=1)
print(data.isnull().sum())
data = data.drop('sex',axis=1)

data['date_confirmation'] = pd.to_datetime(data['date_confirmation'], errors='coerce')
data = data.fillna(method='ffill')
data.date_confirmation = data.date_confirmation.apply(lambda x: int(x.strftime('%d%m%Y')))

pps_df = pps.predictors(data, y="outcome",cross_validation=10,random_seed=123)
pps_df = pps_df.sort_values(by="model_score",axis=0,ascending=False)
pps_df = pd.DataFrame(pps_df)
cols = pps_df[pps_df['ppscore']>0.1]['x'].values

outcome = data.outcome
data= data[cols]
data['outcome'] = outcome
data = data.drop('date_confirmation',axis=1)

le = preprocessing.LabelEncoder()
le = le.fit(data['outcome'])
data.outcome = le.transform(data.outcome.values)


for col in data.columns:
	if data[col].dtype == object:
		print(col)
		le = preprocessing.LabelEncoder()
		le = le.fit(data[col])
		data[col] = le.transform(data[col].values)
		data = data.drop(col,axis=1)

"""#Train-Test Split"""

index_train = random.sample(range(len(data)),int(len(data)*.75))
train = data.iloc[index_train]
test = data.drop(index_train,axis=0)
print(len(train))
print(len(test))
y_train = train['outcome']
y_test = test['outcome']
print(y_test.value_counts())
print(y_train.value_counts())
X_train = train.drop('outcome',axis=1)
X_test = test.drop('outcome',axis=1)

"""#XGBoost Classifier"""

xgb_model = XGBClassifier(learning_rate=0.01, booster='gbtree')

params = {  
            'min_child_weight': [1, 5],
            'max_depth': [3,6,10],
            'n_estimators': [20,50,100,200]
        }

scorers = {
    'f1_weighted' : make_scorer(f1_score, average='weighted'),
    'precision_weighted': make_scorer(precision_score, average='weighted'),
    'recall_weighted': make_scorer(recall_score , average='weighted'),
    'accuracy': make_scorer(accuracy_score),
    'recall[deceased]' : make_scorer(recall_score,average=None,labels=[0])
}

# scorers = ['f1_weighted','precision_weighted','recall_weighted','accuracy']


skf = StratifiedKFold(n_splits=5, shuffle = True)

xgb_clf = GridSearchCV(xgb_model, 
                    param_grid = params,
                    scoring = scorers, 
                    n_jobs = -1, 
                    cv = skf.split(X_train, y_train),
                    refit = 'recall[deceased]')

xgb_clf.fit(X_train, y_train)

xgb = pd.DataFrame(xgb_clf.cv_results_)
xgb = xgb[['param_max_depth',	'param_min_child_weight'	, 'param_n_estimators', 'mean_test_f1_weighted', 'mean_test_precision_weighted', 'mean_test_recall_weighted','mean_test_recall[deceased]', 'mean_test_accuracy', 'rank_test_accuracy']]
xgb = xgb.sort_values(by='rank_test_accuracy')
xgb.to_csv('xgb.csv',index=False)

print(xgb_clf.best_params_)
print(xgb_clf.best_score_)

xgb

y_test_pred = xgb_clf.predict(X_test)
print("Accuracy Test {0:.2f}%".format(100*accuracy_score(y_test,y_test_pred)))
print(classification_report(y_test, y_test_pred))

"""#Random Forest"""

rf_model = RandomForestClassifier(bootstrap=True, warm_start=True, random_state=0)

param_dist = {  
            'n_estimators': [20,50,100,200],
            'max_features': ['auto', 'sqrt', 'log2'],
            'max_depth' : [None,4,6,8,10, 20, 30, 40, 50, 100],
            'criterion' :['gini', 'entropy']
        }

scorers = {
    'f1_weighted' : make_scorer(f1_score, average='weighted'),
    'precision_weighted': make_scorer(precision_score, average='weighted'),
    'recall_weighted': make_scorer(recall_score , average='weighted'),
    'accuracy': make_scorer(accuracy_score),
    'recall[deceased]' : make_scorer(recall_score,average=None,labels=[0])
}


# scorers = ['f1_weighted','precision_weighted','recall_weighted','accuracy']


skf = StratifiedKFold(n_splits=5, shuffle = True)

clf_rf = RandomizedSearchCV(rf_model, 
                    param_dist, 
                    scoring = scorers, 
                    n_jobs = -1, 
                    cv = skf.split(X_train, y_train),
                    n_iter = 30,
                    refit = 'recall[deceased]')

clf_rf.fit(X_train, y_train)

rf = pd.DataFrame(clf_rf.cv_results_)
rf = rf[['param_n_estimators',	'param_max_features',	'param_max_depth'	, 'param_criterion', 'mean_test_f1_weighted', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_recall[deceased]','mean_test_accuracy', 'rank_test_accuracy']]
rf = rf.sort_values(by='rank_test_accuracy')
rf.to_csv('rf.csv',index=False)

print(clf_rf.best_params_)
print(clf_rf.best_score_)

y_test_pred = clf_rf.predict(X_test)
print(accuracy_score(y_test,y_test_pred))
print("Accuracy Test {0:.2f}%".format(100*accuracy_score(y_test,y_test_pred)))
print(classification_report(y_test, y_test_pred))

"""#KNN Classifier"""

knn_model = KNeighborsClassifier()

param_dist = {  
            'n_neighbors': [3,4,5,8,10,15,20,25,30, 40, 50,100],
            'weights': ['uniform', 'distance'],
            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']      
        }

scorers = {
    'f1_weighted' : make_scorer(f1_score, average='weighted'),
    'precision_weighted': make_scorer(precision_score, average='weighted'),
    'recall_weighted': make_scorer(recall_score , average='weighted'),
    'accuracy': make_scorer(accuracy_score),
    'recall[deceased]' : make_scorer(recall_score,average=None,labels=[0])
}


# scorers = ['f1_weighted','precision_weighted','recall_weighted','accuracy']


skf = StratifiedKFold(n_splits=5, shuffle = True)

clf_knn = RandomizedSearchCV(knn_model, 
                    param_dist, 
                    scoring = scorers, 
                    n_jobs = -1, 
                    cv = skf.split(X_train, y_train),
                    n_iter = 30,
                    refit = 'recall[deceased]')

clf_knn.fit(X_train, y_train)

knn = pd.DataFrame(clf_knn.cv_results_)
knn = knn[['param_n_neighbors','param_algorithm',	'param_weights'	, 'mean_test_f1_weighted', 'mean_test_precision_weighted', 'mean_test_recall_weighted','mean_test_recall[deceased]', 'mean_test_accuracy', 'rank_test_accuracy']]
knn = knn.sort_values(by='rank_test_accuracy')
knn.to_csv('knn.csv',index=False)
knn

y_test_pred = clf_knn.predict(X_test)
print(accuracy_score(y_test,y_test_pred) )
print("Accuracy Test {0:.2f}%".format(100*accuracy_score(y_test,y_test_pred)))
print(classification_report(y_test, y_test_pred))

print(clf_knn.best_params_)
print(clf_knn.best_score_)